[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip2, hip3, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip2, hip3, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip1, hip3, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip1, hip3, hip2})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip3, hip1, hip2, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip3, hip1, hip2, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip3, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip3, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip3, hip2, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip3, hip2, hip4})]
[HyperEdge({hip4, ankle4}), HyperEdge({ankle1, hip1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip3, hip4, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({ankle1, hip1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip3, hip4, hip1, hip2})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip3, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip3, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip3, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip3, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({hip1, ankle1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip4, hip3})]
[HyperEdge({ankle4, hip4}), HyperEdge({hip1, ankle1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip4, hip3})]
[HyperEdge({hip4, ankle4}), HyperEdge({ankle1, hip1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip2, hip4, hip3, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({ankle1, hip1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip2, hip4, hip3, hip1})]
[HyperEdge({ankle4, hip4}), HyperEdge({hip1, ankle1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip4, hip3})]
[HyperEdge({ankle4, hip4}), HyperEdge({hip1, ankle1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip4, hip3})]
[HyperEdge({ankle4, hip4}), HyperEdge({hip1, ankle1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip4, hip3})]
[HyperEdge({ankle4, hip4}), HyperEdge({hip1, ankle1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip4, hip3})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip4, hip2, hip3})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip4, hip2, hip3})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip4, hip2, hip3})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip4, hip2, hip3})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip3, hip4, hip2})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip3, hip4, hip2})]
/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  nan
done_episodes_costs_agent_aver:  nan
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
done_episodes_costs_aver:  1.0
done_episodes_costs_agent_aver:  [0. 0.]
Process Process-10:
Process Process-8:
Process Process-9:
Process Process-11:
Process Process-3:
Process Process-4:
Process Process-5:
Process Process-7:
Process Process-2:
Process Process-17:
Process Process-6:
Process Process-15:
Process Process-14:
Process Process-13:
Process Process-16:
Process Process-12:
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
KeyboardInterrupt
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
Traceback (most recent call last):
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
Traceback (most recent call last):
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
KeyboardInterrupt
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 203, in step
    return self.get_obs(), self.get_state(), rewards, dones, infos, self.get_avail_actions()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 246, in get_state
    state = self.env._get_obs()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 77, in _get_obs
    [y_off],
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "<__array_function__ internals>", line 2, in concatenate
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 203, in step
    return self.get_obs(), self.get_state(), rewards, dones, infos, self.get_avail_actions()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 207, in get_obs
    state = self.env._get_obs()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 77, in _get_obs
    [y_off],
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 203, in step
    return self.get_obs(), self.get_state(), rewards, dones, infos, self.get_avail_actions()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 203, in step
    return self.get_obs(), self.get_state(), rewards, dones, infos, self.get_avail_actions()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 253, in get_state
    state_i = (state_i - np.mean(state_i)) / np.std(state_i)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 253, in get_state
    state_i = (state_i - np.mean(state_i)) / np.std(state_i)
  File "<__array_function__ internals>", line 6, in std
  File "<__array_function__ internals>", line 6, in std
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 3582, in std
    **kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 3582, in std
    **kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 263, in _std
    keepdims=keepdims, where=where)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 263, in _std
    keepdims=keepdims, where=where)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 247, in _var
    rcount = um.maximum(rcount - ddof, 0)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 244, in _var
    ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 203, in step
    return self.get_obs(), self.get_state(), rewards, dones, infos, self.get_avail_actions()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 203, in step
    return self.get_obs(), self.get_state(), rewards, dones, infos, self.get_avail_actions()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 203, in step
    return self.get_obs(), self.get_state(), rewards, dones, infos, self.get_avail_actions()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 216, in get_obs
    obs_i = (obs_i - np.mean(obs_i)) / np.std(obs_i)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 253, in get_state
    state_i = (state_i - np.mean(state_i)) / np.std(state_i)
  File "<__array_function__ internals>", line 6, in std
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 253, in get_state
    state_i = (state_i - np.mean(state_i)) / np.std(state_i)
  File "<__array_function__ internals>", line 6, in std
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 3582, in std
    **kwargs)
  File "<__array_function__ internals>", line 6, in std
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 3582, in std
    **kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 263, in _std
    keepdims=keepdims, where=where)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 3582, in std
    **kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 268, in _std
    ret = ret.dtype.type(um.sqrt(ret))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 215, in _var
    if rcount.ndim == 0:
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 263, in _std
    keepdims=keepdims, where=where)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 244, in _var
    ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 58, in step
    cost=cost,
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
KeyboardInterrupt
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 203, in step
    return self.get_obs(), self.get_state(), rewards, dones, infos, self.get_avail_actions()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 262, in get_avail_actions
    return np.ones(shape=(self.n_agents, self.n_actions,))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/numeric.py", line 149, in ones
    @set_array_function_like_doc
KeyboardInterrupt
Traceback (most recent call last):
  File "train/train_mujoco.py", line 197, in <module>
    main(sys.argv[1:])
  File "train/train_mujoco.py", line 182, in main
    runner.run()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/runner/separated/mujoco_runner_macpo.py", line 51, in run
    obs, share_obs, rewards, costs, dones, infos, _ = self.envs.step(actions)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 108, in step
    return self.step_wait()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 375, in step_wait
    results = [remote.recv() for remote in self.remotes]
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 375, in <listcomp>
    results = [remote.recv() for remote in self.remotes]
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
