[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({ankle3, hip3}), HyperEdge({hip4, hip1, hip2, hip3})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({ankle3, hip3}), HyperEdge({hip4, hip1, hip2, hip3})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({ankle2, hip2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip2, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({ankle2, hip2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip2, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({ankle1, hip1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({ankle1, hip1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip2, hip1, hip3})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip2, hip1, hip3})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip2, hip4, hip3, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip2, hip4, hip3, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip2, hip4, hip3, hip1})][HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip2, hip4, hip3, hip1})][HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip2, hip4, hip3, hip1})]


[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip2, hip4, hip3, hip1})][HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip2, hip4, hip3, hip1})]

[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip2, hip4, hip3, hip1})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip2, hip3, hip1, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip2, hip3, hip1, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip2, hip3, hip1, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip2, hip3, hip1, hip4})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip1, hip4, hip3, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip1, hip4, hip3, hip2})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip3, hip2, hip4, hip1})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip3, hip2, hip4, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip1, hip3, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip1, hip3, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip3, hip4, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip3, hip4, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip3, hip4, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip3, hip4, hip1, hip2})]
cost_env: nan, cost_agent: nan
/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: nan, cost_agent: nan
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
cost_env: 1.0, cost_agent: [0. 0.]
Process Process-13:
Process Process-15:
Process Process-5:
Process Process-4:
Process Process-14:
Process Process-16:
Process Process-10:
Process Process-3:
Process Process-9:
Process Process-8:
Process Process-12:
Process Process-17:
Process Process-11:
Process Process-2:
Process Process-6:
Process Process-7:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
KeyboardInterrupt
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
KeyboardInterrupt
KeyboardInterrupt
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
Traceback (most recent call last):
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
KeyboardInterrupt
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
Traceback (most recent call last):
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
KeyboardInterrupt
KeyboardInterrupt
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
KeyboardInterrupt
Traceback (most recent call last):
  File "train/train_mujoco.py", line 197, in <module>
    main(sys.argv[1:])
  File "train/train_mujoco.py", line 182, in main
    runner.run()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/runner/separated/mujoco_runner_macpo.py", line 51, in run
    obs, share_obs, rewards, costs, dones, infos, _ = self.envs.step(actions)
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 108, in step
    return self.step_wait()
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 375, in step_wait
    results = [remote.recv() for remote in self.remotes]
  File "/home/zhi.zheng/zz/RL/Multi-Agent-Constrained-Policy-Optimisation/MACPO/macpo/envs/env_wrappers.py", line 375, in <listcomp>
    results = [remote.recv() for remote in self.remotes]
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhi.zheng/micromamba/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
