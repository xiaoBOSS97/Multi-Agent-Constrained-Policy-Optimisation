[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip2, hip1, hip3})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip2, hip1, hip3})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({hip3, ankle3}), HyperEdge({hip1, hip3, hip4, hip2})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({hip3, ankle3}), HyperEdge({hip1, hip3, hip4, hip2})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip3, hip4, hip2})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip3, hip4, hip2})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip2, hip3, hip4, hip1})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip2, hip3, hip4, hip1})]
[HyperEdge({ankle4, hip4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip2, hip1, hip3, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip2, hip1, hip3, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({ankle3, hip3}), HyperEdge({hip2, hip1, hip3, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({ankle3, hip3}), HyperEdge({hip2, hip1, hip3, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({hip1, ankle1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip3, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({hip1, ankle1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip1, hip2, hip3, hip4})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip1, hip2, hip3})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip1, hip2, hip3})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip3, hip1, hip2, hip4})]
[HyperEdge({ankle4, hip4}), HyperEdge({ankle1, hip1}), HyperEdge({ankle2, hip2}), HyperEdge({ankle3, hip3}), HyperEdge({hip3, hip1, hip2, hip4})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip1, hip2})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip3, hip4, hip2, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip3, hip4, hip2, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip2, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip4, hip3, hip2, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip3, hip4, hip2, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip3, hip4, hip2, hip1})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip1, hip4, hip2, hip3})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip1, hip4, hip2, hip3})]
share_observation_space:  [Box(31,), Box(31,)]
observation_space:  [Box(31,), Box(31,)]
action_space:  (Box(4,), Box(4,))
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip1, hip4, hip2, hip3})]
[HyperEdge({hip4, ankle4}), HyperEdge({hip1, ankle1}), HyperEdge({hip2, ankle2}), HyperEdge({hip3, ankle3}), HyperEdge({hip1, hip4, hip2, hip3})]

 Scenario Ant-v2 Algo mappo_pcrpo Exp rnn updates 0/625 episodes, total num timesteps 16000/10000000, FPS 2091.

average_step_rewards is 0.47806239128112793.
some episodes done, average rewards: 154.4567141519982, average costs: 24.470588235294116

 Scenario Ant-v2 Algo mappo_pcrpo Exp rnn updates 5/625 episodes, total num timesteps 96000/10000000, FPS 2141.

average_step_rewards is 0.471530944108963.
some episodes done, average rewards: 209.22809995147614, average costs: 37.945945945945944

 Scenario Ant-v2 Algo mappo_pcrpo Exp rnn updates 10/625 episodes, total num timesteps 176000/10000000, FPS 2137.

average_step_rewards is 0.4802439212799072.
some episodes done, average rewards: 219.9441397753149, average costs: 86.13513513513513

 Scenario Ant-v2 Algo mappo_pcrpo Exp rnn updates 15/625 episodes, total num timesteps 256000/10000000, FPS 2132.

average_step_rewards is 0.47058528661727905.
some episodes done, average rewards: 177.20783198460344, average costs: 43.6

 Scenario Ant-v2 Algo mappo_pcrpo Exp rnn updates 20/625 episodes, total num timesteps 336000/10000000, FPS 2127.

average_step_rewards is 0.46728020906448364.
some episodes done, average rewards: 235.8918475826004, average costs: 14.444444444444445

 Scenario Ant-v2 Algo mappo_pcrpo Exp rnn updates 25/625 episodes, total num timesteps 416000/10000000, FPS 2123.

average_step_rewards is 0.4503266215324402.
some episodes done, average rewards: 201.81093568365537, average costs: 41.05128205128205

 Scenario Ant-v2 Algo mappo_pcrpo Exp rnn updates 30/625 episodes, total num timesteps 496000/10000000, FPS 2120.

average_step_rewards is 0.46277034282684326.
some episodes done, average rewards: 188.57765950856256, average costs: 31.783783783783782

 Scenario Ant-v2 Algo mappo_pcrpo Exp rnn updates 35/625 episodes, total num timesteps 576000/10000000, FPS 2123.

average_step_rewards is 0.46847814321517944.
some episodes done, average rewards: 143.70645938811998, average costs: 26.392156862745097

 Scenario Ant-v2 Algo mappo_pcrpo Exp rnn updates 40/625 episodes, total num timesteps 656000/10000000, FPS 2120.

average_step_rewards is 0.48785412311553955.
some episodes done, average rewards: 211.44444289469078, average costs: 44.24390243902439

 Scenario Ant-v2 Algo mappo_pcrpo Exp rnn updates 45/625 episodes, total num timesteps 736000/10000000, FPS 2117.

average_step_rewards is 0.48495733737945557.
some episodes done, average rewards: 246.58944350426043, average costs: 44.885714285714286
Process Process-8:
Process Process-16:
Process Process-14:
Process Process-15:
Process Process-17:
Process Process-9:
Process Process-12:
Process Process-11:
Process Process-7:
Process Process-6:
Process Process-5:
Process Process-4:
Process Process-10:
Process Process-3:
Process Process-2:
Process Process-13:
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
Traceback (most recent call last):
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
Traceback (most recent call last):
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
Traceback (most recent call last):
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 203, in step
    return self.get_obs(), self.get_state(), rewards, dones, infos, self.get_avail_actions()
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 207, in get_obs
    state = self.env._get_obs()
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 203, in step
    return self.get_obs(), self.get_state(), rewards, dones, infos, self.get_avail_actions()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 62, in _get_obs
    x = self.sim.data.qpos.flat[0]
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 246, in get_state
    state = self.env._get_obs()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 63, in _get_obs
    y = self.sim.data.qpos.flat[1]
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
KeyboardInterrupt
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
KeyboardInterrupt
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
KeyboardInterrupt
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 305, in shareworker
    cmd, data = remote.recv()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
Traceback (most recent call last):
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
KeyboardInterrupt
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 15, in step
    self.do_simulation(a, self.frame_skip)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_env.py", line 125, in do_simulation
    self.sim.step()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 315, in shareworker
    remote.send((ob, s_ob, reward, done, info, available_actions))
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 203, in step
    return self.get_obs(), self.get_state(), rewards, dones, infos, self.get_avail_actions()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 253, in get_state
    state_i = (state_i - np.mean(state_i)) / np.std(state_i)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "<__array_function__ internals>", line 6, in std
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 3582, in std
    **kwargs)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 263, in _std
    keepdims=keepdims, where=where)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 203, in step
    return self.get_obs(), self.get_state(), rewards, dones, infos, self.get_avail_actions()
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 203, in step
    return self.get_obs(), self.get_state(), rewards, dones, infos, self.get_avail_actions()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 222, in _var
    arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 253, in get_state
    state_i = (state_i - np.mean(state_i)) / np.std(state_i)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 216, in get_obs
    obs_i = (obs_i - np.mean(obs_i)) / np.std(obs_i)
  File "<__array_function__ internals>", line 6, in mean
  File "<__array_function__ internals>", line 6, in std
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 3441, in mean
    out=out, **kwargs)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 3582, in std
    **kwargs)
KeyboardInterrupt
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 167, in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 263, in _std
    keepdims=keepdims, where=where)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 74, in _count_reduce_items
    items = nt.intp(1)
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 307, in shareworker
    ob, s_ob, reward, done, info, available_actions = env.step(data)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/mujoco_multi.py", line 180, in step
    obs_n, reward_n, done_n, info_n = self.wrapped_env.step(flat_actions)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/gym/core.py", line 285, in step
    return self.env.step(self.action(action))
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 16, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/safety_ma_mujoco/safety_multiagent_mujoco/ant.py", line 22, in step
    np.square(np.clip(self.sim.data.cfrc_ext, -1, 1)))
  File "<__array_function__ internals>", line 6, in clip
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 2115, in clip
    return _wrapfunc(a, 'clip', a_min, a_max, out=out, **kwargs)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 57, in _wrapfunc
    return bound(*args, **kwds)
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/site-packages/numpy/core/_methods.py", line 160, in _clip
    um.clip, a, min, max, out=out, casting=casting, **kwargs)
KeyboardInterrupt
Traceback (most recent call last):
  File "train/train_mujoco.py", line 197, in <module>
    main(sys.argv[1:])
  File "train/train_mujoco.py", line 182, in main
    runner.run()
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/runner/separated/mujoco_runner_mappo_pcrpo.py", line 43, in run
    obs, share_obs, rewards, costs, dones, infos, _ = self.envs.step(actions)
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 108, in step
    return self.step_wait()
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 375, in step_wait
    results = [remote.recv() for remote in self.remotes]
  File "/home/zhi.zheng/zz/Multi-Agent-Constrained-Policy-Optimisation/MAPPO-PCRPO/mappo_pcrpo/envs/env_wrappers.py", line 375, in <listcomp>
    results = [remote.recv() for remote in self.remotes]
  File "/home/zhi.zheng/anaconda3/envs/macpo/lib/python3.7/multiprocessing/connection.py", line 251, in recv
    return _ForkingPickler.loads(buf.getbuffer())
KeyboardInterrupt
